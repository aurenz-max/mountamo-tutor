# Product Requirements Document: Enhanced Assessment Feedback

**Author:** Kilo Code
**Version:** 1.2
**Date:** 2025-09-17
**Status:** Draft

## 1. Introduction & Vision

Currently, students receive basic, quantitative feedback after an assessment. This minimal feedback fails to capitalize on a crucial learning opportunity. The vision for Enhanced Assessment Feedback is to transform the results page from a score report into a personalized, actionable, and encouraging learning tool.

We will achieve this by:
1.  **AI-Powered Holistic Summary:** Using a large language model (LLM) to provide a narrative summary of the student's performance, comparing their results against the initial assessment `blueprint`.
2.  **Detailed Breakdown:** Surfacing the rich, detailed review data already generated by the `review_service` to provide qualitative insights at the question level.

This feature will deepen engagement, increase student agency, and ultimately drive better learning outcomes.

## 2. Goals

*   **Primary Goal:** Provide an AI-generated, holistic summary and actionable, qualitative feedback to help students understand their strengths and weaknesses.
*   **Secondary Goal:** Increase student motivation by highlighting progress and providing clear next steps.
*   **Business Goal:** Improve student retention and perceived value of the platform by offering a superior, more personalized learning experience.

## 3. User Personas

*   **Alex (The Struggling Student):** Needs to see the big picture of where to start without feeling overwhelmed.
*   **Priya (The Ambitious Student):** Wants to understand the nuances of her performance across different categories like "weak spots" and "new frontiers".
*   **David (The "Good Enough" Student):** Can be motivated by seeing a narrative of his progress and what's next.

## 4. Feature Requirements

### 4.1. NEW: AI-Powered Overall Summary

At the top of the results page, we will display a new "Summary" card. This card will contain a concise, narrative summary generated by a Gemini Flash model.

*   **Input to the LLM:**
    1.  The original assessment `blueprint`, especially the `category_breakdown` (e.g., weak_spots, new_frontiers) and the list of `selected_subskills`.
    2.  The final assessment results, including the overall score and the per-skill performance.
*   **LLM Prompt Goal:** "You are a friendly and encouraging tutor. Based on the student's learning goals for this assessment (the blueprint) and their final performance (the results), provide a 2-3 sentence summary. Highlight how they performed on their 'weak spots' and how they did on 'new frontiers'. End with an encouraging sentence about next steps."
*   **Example Output:** "Great work on this assessment! You showed strong improvement in 'Print Concepts', a weak spot we wanted to focus on. You also did a fantastic job on your first try with 'Parts of Speech', a new frontier for you. Let's keep up the momentum and review the few questions you missed."
*   **UI:** Displayed in a prominent `Card` component at the top of the page.

### 4.2. High-Level Summary (formerly 4.1)

The header will provide a more insightful summary.

*   **Overall Performance Quote:** A dynamic, encouraging, one-sentence summary of their performance.
    *   **90-100%:** "Outstanding work! You have a strong command of these concepts."
    *   **75-89%:** "Great job! You have a solid understanding, and with a little more practice, you can master this material."
    *   **50-74%:** "A good start! You're building a foundation. Let's review a few areas to strengthen your understanding."
    *   **<50%:** "You've taken an important first step. This is a great opportunity to identify where we can focus and build up your skills."

### 4.3. Skill-by-Skill Analysis (The Core of the Feature)

The current "Skill Breakdown" will be replaced with a more detailed "Skill Analysis" section. For each skill tested in the assessment, we will provide:

1.  **Quantitative Score:** (e.g., "2/3 Correct")
2.  **Qualitative Performance Label:** (Mastered, Proficient, Developing, Needs Review)
    *   **Mastered (100%):** "You've mastered this skill. You consistently applied the concepts correctly."
    *   **Proficient (>=75% and <100%):** "You are proficient in this skill. You have a good handle on the main concepts but made a small slip."
    *   **Developing (>=50% and <75%):** "You are developing this skill. You understand some of the concepts but are missing some key ideas."
    *   **Needs Review (<50%):** "This skill needs review. Let's go back to the fundamentals to build a stronger foundation."
3.  **Actionable Insight & "Why":** A short, auto-generated sentence.
    *   **Mastered:** "You're ready for a new challenge."
    *   **Proficient:** "Review the question you missed to solidify your understanding."
    *   **Developing & Needs Review:** "Let's revisit the core lessons for this skill to build your confidence."
4.  **"Next Step" Button:** A specific, context-aware call to action.
    *   **Mastered:** "Practice a related skill" or "Try a harder problem set."
    *   **Proficient/Developing:** "Review incorrect answers."
    *   **Needs Review:** "Re-learn this concept" (links to the relevant lesson/material).


### 4.4. "Let's Review" Section

A new section dedicated to reviewing incorrect answers.

*   Lists each question the student answered incorrectly.
*   For each incorrect question, it displays data sourced directly from the `full_review` object in Cosmos DB:
    *   The question itself (from `problem_content.question`).
    *   "Your answer" (from `observation.selected_answer_text`).
    *   "Correct answer" (The text of the option matching `problem_content.correct_option_id`).
    *   A clear, concise **rationale** (from `feedback.guidance` or `problem_content.rationale`).
    *   A "praise" or "encouragement" message (from `feedback.praise` or `feedback.encouragement`).

### 4.5. UI/UX

*   Use accordions or expandable cards for the "Skill Analysis" and "Let's Review" sections to keep the initial view clean.
*   The UI should be visually engaging, using colors and icons to intuitively convey performance (e.g., green for mastered, yellow for proficient, red for needs review).

### 4.6. Data & API Requirements
The `get_assessment_summary` endpoint in [`backend/app/api/endpoints/assessments.py`](backend/app/api/endpoints/assessments.py:1) will need to be enhanced.

**NEW Top-Level Field in API Response:**

```json
{
  "assessment_id": "...",
  "ai_summary": "Great work on this assessment! You showed strong improvement in 'Print Concepts', a weak spot we wanted to focus on...",
  "skill_analysis": [ ... ],
  "review_items": [ ... ]
  // ... other existing fields
}
```

The `skill_analysis` and `review_items` structures remain as defined in v1.1 of this PRD.
```json
{
  "skill_name": "Skill Name",
  "total_questions": 3,
  "correct_answers": 2,
  "percentage": 66.7
}
```

**NEW `skill_analysis` object (in API response):**
```json
{
  "skill_id": "SKILL_ID_001",
  "skill_name": "Skill Name",
  "total_questions": 3,
  "correct_count": 2,
  "performance_label": "Developing",
  "insight_text": "You understand some of the concepts but are missing some key ideas.",
  "next_step": {
    "text": "Review incorrect answers",
    "link": "/practice/review?assessment_id=[assessment_id]&skill_id=SKILL_ID_001"
  }
}
```

**NEW `review_items` array (in API response):**
This will be constructed by fetching the `problem_review` documents from Cosmos DB for each incorrect answer in the assessment.

```json
[
  {
    "problem_id": "PROBLEM_123",
    "question_text": "What is the capital of France?",
    "your_answer_text": "Berlin",
    "correct_answer_text": "Paris",
    "analysis": {
        "understanding": "Student confused the capitals of Germany and France, suggesting a need to review European geography.",
        "approach": "Student selected an option from the provided multiple choices."
    },
    "feedback": {
        "praise": "Good try! It's easy to mix those up.",
        "guidance": "Paris is the capital of France. Berlin is the capital of Germany.",
        "encouragement": "Let's review the map to get these locked in!"
    },
    "related_skill_id": "SKILL_ID_002",
    "lesson_link": "/lessons/geography/capitals"
  }
]
```
*Your `your_answer` is in `observation.selected_answer_text`.*

## 5. Technical Implementation Plan

### Phase 1: Backend API Changes

1.  **Integrate Gemini:** Create a new service or helper function that can be called by `assessment_service`. This function will be responsible for calling the Gemini Flash API.
2.  **Update `score_assessment` in `assessment_service.py`:**
    *   After the assessment is scored, retrieve the original `assessment` document from Cosmos DB to access the `blueprint`.
    *   Compile the necessary data: the `blueprint` and the final `submission_result`.
    *   Pass this data to the new Gemini service to generate the `ai_summary`.
    *   Include the returned `ai_summary` in the `submission_result` object that is saved to the completed assessment document in Cosmos DB. This ensures we only generate the summary once.
3.  **Update `get_assessment_summary`:**
    *   This function will now simply read the `ai_summary` from the completed assessment document along with the other data (`review_items`, `skill_analysis`). This avoids making a new LLM call every time the results are viewed.
4.  **Confirm Data Logging:** Verify that a `problem_review` document is saved for every assessment question to populate the `review_items` section.

### Phase 2: Frontend Implementation

1.  **Update Frontend Data Model:** Add `ai_summary: string;` to the `AssessmentSummary` interface in [`my-tutoring-app/src/app/assessments/results/[assessment_id]/page.tsx`](my-tutoring-app/src/app/assessments/results/[assessment_id]/page.tsx).
2.  **Build New `AISummaryCard` Component:** This component will display the `ai_summary` text.
3.  **Add to Results Page:** Place the new `AISummaryCard` in a prominent position at the top of the assessment results page.

## 6. Success Metrics

*   **Engagement:** Increase in the click-through rate on "Next Step" buttons by 25%.
*   **Performance:** A 10% improvement in scores on subsequent assessments covering the same skills.
*   **User Satisfaction:** Positive qualitative feedback from user surveys, specifically mentioning the helpfulness of the summary.