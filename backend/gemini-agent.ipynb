{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab34616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #7f8c8d; font-weight: bold;'></span> ==================== STARTING RESEARCH ====================</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== STARTING RESEARCH ====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #3498db; font-weight: bold;'>[15:25:02] </span> Research topic: From the perspective of a 5 year old, can you explain how excavators work?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:02] Research topic: From the perspective of a 5 year old, can you explain how excavators work?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #3498db; font-weight: bold;'>[15:25:02] </span> Target audience: 5 year old children</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:02] Target audience: 5 year old children\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802d6c0aa924417181f6f19db22d0dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Research in progress: 0steps [00:00, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #7f8c8d; font-weight: bold;'>[15:25:04] </span> Generating research queries for: From the perspective of a 5 year old, can you explain how excavators work?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:04] [research_manager] </span> Message: Okay, I understand the research assignment. I will follow the mandatory workflow precisely to resear...</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:04] Generating research queries for: From the perspective of a 5 year old, can you explain how excavators work?\n",
      "[15:25:04] [research_manager] Message: Okay, I understand the research assignment. I will follow the mandatory workflow precisely to resear...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:04] [research_manager] </span> Generating queries for: From the perspective of a 5 year old, can you explain how excavators work?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:04] [research_manager] Generating queries for: From the perspective of a 5 year old, can you explain how excavators work?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:04] [research_manager] </span> Research queries generated</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:04] [research_manager] Research queries generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:06] [research_manager] </span> Message: Okay, I have the query templates. Now I will proceed with the research phase by performing 5 separat...</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:06] [research_manager] Message: Okay, I have the query templates. Now I will proceed with the research phase by performing 5 separat...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:06] [research_manager] </span> WARNING: Empty search query detected</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:06] [research_manager] WARNING: Empty search query detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:09] [research_manager] </span> Received search results (search #0)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:09] [research_manager] Received search results (search #0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:11] [research_manager] </span> Message: Now I will perform the second search.\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:11] [research_manager] Message: Now I will perform the second search.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:11] [research_manager] </span> WARNING: Empty search query detected</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:11] [research_manager] WARNING: Empty search query detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:27] [research_manager] </span> Received search results (search #0)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:27] [research_manager] Received search results (search #0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:28] [research_manager] </span> Message: Here is my third search query:\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:28] [research_manager] Message: Here is my third search query:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:28] [research_manager] </span> WARNING: Empty search query detected</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:28] [research_manager] WARNING: Empty search query detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:31] [research_manager] </span> Received search results (search #0)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:31] [research_manager] Received search results (search #0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:32] [research_manager] </span> Message: Here is my fourth search query:\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:32] [research_manager] Message: Here is my fourth search query:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:32] [research_manager] </span> WARNING: Empty search query detected</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:32] [research_manager] WARNING: Empty search query detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:39] [research_manager] </span> Received search results (search #0)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:39] [research_manager] Received search results (search #0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:39] [research_manager] </span> Message: Here is my fifth and final search query:\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:39] [research_manager] Message: Here is my fifth and final search query:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:39] [research_manager] </span> WARNING: Empty search query detected</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:39] [research_manager] WARNING: Empty search query detected\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:25:56] [research_manager] </span> Received search results (search #0)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:56] [research_manager] Received search results (search #0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #7f8c8d; font-weight: bold;'>[15:26:01] </span> Finalizing report for 5 year old children audience</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:26:01] [research_manager] </span> Finalizing report for 5 year old children audience: Excavators are big machines that are like giant sh...</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:01] Finalizing report for 5 year old children audience\n",
      "[15:26:01] [research_manager] Finalizing report for 5 year old children audience: Excavators are big machines that are like giant sh...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:26:01] [research_manager] </span> Report format provided</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:01] [research_manager] Report format provided\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:26:08] [research_manager] </span> Final report detected (2465 chars)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] [research_manager] Final report detected (2465 chars)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:26:08] [research_manager] </span> Substantial response detected (2465 chars)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] [research_manager] Substantial response detected (2465 chars)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #9b59b6; font-weight: bold;'>[15:26:08] [research_manager] </span> Message: ### FINAL RESEARCH REPORT ###\n",
       "\n",
       "**1. Introduction**\n",
       "Excavators are really, really big machines! They ...</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] [research_manager] Message: ### FINAL RESEARCH REPORT ###\n",
      "\n",
      "**1. Introduction**\n",
      "Excavators are really, really big machines! They ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #7f8c8d; font-weight: bold;'></span> ==================== FINAL REPORT ====================</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== FINAL REPORT ====================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Research Report"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### FINAL RESEARCH REPORT ###\n",
       "\n",
       "**1. Introduction**\n",
       "Excavators are really, really big machines! They look like giant toy trucks with a big arm. They are super cool because they help people build things like houses and roads by digging in the dirt and moving big piles of stuff. [Search 1, 4]\n",
       "\n",
       "**2. How It Works**\n",
       "Imagine an excavator is a strong robot helper! A driver sits inside a little room called the cab and uses special handles, like joysticks in a video game, to tell the excavator what to do. [Search 1, 2, 3, 4, 5] The handles make the big arm move up, down, and side to side. At the end of the arm is a giant scoop, called a bucket. The driver makes the bucket dig into the dirt, scoop it up, lift it high, and then dump it somewhere else! [Search 1, 3, 5] The top part of the excavator can even spin all the way around so it can work in different spots without moving its feet! [Search 1, 4]\n",
       "\n",
       "**3. Key Parts**\n",
       "Excavators have important parts that help them do their job:\n",
       "*   **Cab:** This is the little house where the driver sits to control everything. [Search 2, 4, 5]\n",
       "*   **Arm:** This is the long part that reaches out. It's like the excavator's strong arm! It has two parts that bend, the boom and the stick. [Search 2, 5]\n",
       "*   **Bucket:** This is the big scoop at the end of the arm. It's like a super strong spoon that digs and picks up dirt, rocks, and sand. [Search 1, 2, 3, 4, 5]\n",
       "*   **Tracks:** These are like giant tank treads or big feet that help the excavator move around, even on bumpy ground or mud. [Search 2, 4, 5]\n",
       "*   **Engine:** This part makes the excavator go and gives it power, kind of like the engine in a car. [Search 2]\n",
       "*   **Hydraulics:** This is a special system that uses fluid to make the arm and bucket move with lots of strength! [Search 2, 3, 5]\n",
       "*   **Counterweight:** This is a heavy part at the back that helps the excavator stay balanced when it lifts heavy things so it doesn't tip over! [Search 2]\n",
       "\n",
       "**4. Real World Examples**\n",
       "Excavators are busy helpers in many places!\n",
       "*   They dig big holes when people are building new houses or swimming pools. [Search 1, 4, 5]\n",
       "*   They help build roads by moving lots of dirt and rocks. [Search 1, 4]\n",
       "*   They can move really big and heavy things that people can't lift. [Search 4, 5]\n",
       "\n",
       "**5. Fun Facts**\n",
       "*   Sometimes excavators are called diggers or backhoes! [Search 4]\n",
       "*   They can be really big, some as heavy as lots and lots of elephants! [Search 5]\n",
       "\n",
       "### END OF REPORT ###"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Research Report\n",
      "==================================================\n",
      "### FINAL RESEARCH REPORT ###\n",
      "\n",
      "**1. Introduction**\n",
      "Excavators are really, really big machines! They look like giant toy trucks with a big arm. They are super cool because they help people build things like houses and roads by digging in the dirt and moving big piles of stuff. [Search 1, 4]\n",
      "\n",
      "**2. How It Works**\n",
      "Imagine an excavator is a strong robot helper! A driver sits inside a little room called the cab and uses special handles, like joysticks in a video game, to tell the excavator what to do. [Search 1, 2, 3, 4, 5] The handles make the big arm move up, down, and side to side. At the end of the arm is a giant scoop, called a bucket. The driver makes the bucket dig into the dirt, scoop it up, lift it high, and then dump it somewhere else! [Search 1, 3, 5] The top part of the excavator can even spin all the way around so it can work in different spots without moving its feet! [Search 1, 4]\n",
      "\n",
      "**3. Key Parts**\n",
      "Excavators have important parts that help them do their job:\n",
      "*   **Cab:** This is the little house where the driver sits to control everything. [Search 2, 4, 5]\n",
      "*   **Arm:** This is the long part that reaches out. It's like the excavator's strong arm! It has two parts that bend, the boom and the stick. [Search 2, 5]\n",
      "*   **Bucket:** This is the big scoop at the end of the arm. It's like a super strong spoon that digs and picks up dirt, rocks, and sand. [Search 1, 2, 3, 4, 5]\n",
      "*   **Tracks:** These are like giant tank treads or big feet that help the excavator move around, even on bumpy ground or mud. [Search 2, 4, 5]\n",
      "*   **Engine:** This part makes the excavator go and gives it power, kind of like the engine in a car. [Search 2]\n",
      "*   **Hydraulics:** This is a special system that uses fluid to make the arm and bucket move with lots of strength! [Search 2, 3, 5]\n",
      "*   **Counterweight:** This is a heavy part at the back that helps the excavator stay balanced when it lifts heavy things so it doesn't tip over! [Search 2]\n",
      "\n",
      "**4. Real World Examples**\n",
      "Excavators are busy helpers in many places!\n",
      "*   They dig big holes when people are building new houses or swimming pools. [Search 1, 4, 5]\n",
      "*   They help build roads by moving lots of dirt and rocks. [Search 1, 4]\n",
      "*   They can move really big and heavy things that people can't lift. [Search 4, 5]\n",
      "\n",
      "**5. Fun Facts**\n",
      "*   Sometimes excavators are called diggers or backhoes! [Search 4]\n",
      "*   They can be really big, some as heavy as lots and lots of elephants! [Search 5]\n",
      "\n",
      "### END OF REPORT ###\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #7f8c8d; font-weight: bold;'>[15:26:08] </span> Research results saved to research_from_the_perspective_of_a_20250501_152608.json</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] Research results saved to research_from_the_perspective_of_a_20250501_152608.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #1abc9c; font-weight: bold;'>[15:26:08] </span> Report saved (2465 chars, 0 steps)</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] Report saved (2465 chars, 0 steps)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom: 10px;'><span style='color: #3498db; font-weight: bold;'>[15:26:08] </span> Research completed and saved to research_from_the_perspective_of_a_20250501_152608.json</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:08] Research completed and saved to research_from_the_perspective_of_a_20250501_152608.json\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.agent_tool import AgentTool\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.tools import FunctionTool\n",
    "from google.genai import types\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import traceback\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# Import settings from your config module\n",
    "from app.core.config import settings\n",
    "\n",
    "# Set up Gemini API key from settings\n",
    "os.environ[\"GOOGLE_API_KEY\"] = settings.GEMINI_GENERATE_KEY\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"  # Explicitly disable Vertex AI authentication\n",
    "\n",
    "# Helper functions for displaying research progress\n",
    "def format_time():\n",
    "    \"\"\"Return a formatted timestamp for logging.\"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "\n",
    "def display_log(message, agent_name=None, message_type=\"info\", include_timestamp=True):\n",
    "    \"\"\"Display a formatted log message in the notebook.\"\"\"\n",
    "    colors = {\n",
    "        \"info\": \"#3498db\",  # Blue\n",
    "        \"search\": \"#e67e22\",  # Orange\n",
    "        \"result\": \"#2ecc71\",  # Green\n",
    "        \"error\": \"#e74c3c\",  # Red\n",
    "        \"warning\": \"#f39c12\",  # Amber\n",
    "        \"manager\": \"#9b59b6\",  # Purple\n",
    "        \"search_agent\": \"#f1c40f\",  # Yellow\n",
    "        \"system\": \"#7f8c8d\",  # Gray\n",
    "        \"debug\": \"#1abc9c\"   # Teal\n",
    "    }\n",
    "    \n",
    "    if agent_name:\n",
    "        if agent_name.lower() in [\"research_manager\", \"manager\"]:\n",
    "            message_type = \"manager\"\n",
    "        elif agent_name.lower() in [\"search_agent\", \"search\"]:\n",
    "            message_type = \"search_agent\"\n",
    "    \n",
    "    color = colors.get(message_type, colors[\"info\"])\n",
    "    prefix = f\"[{format_time()}] \" if include_timestamp else \"\"\n",
    "    if agent_name:\n",
    "        prefix += f\"[{agent_name}] \"\n",
    "    \n",
    "    html = f\"<div style='margin-bottom: 10px;'><span style='color: {color}; font-weight: bold;'>{prefix}</span> {message}</div>\"\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Also log to console for backup\n",
    "    console_prefix = f\"[{format_time()}] \" if include_timestamp else \"\"\n",
    "    if agent_name:\n",
    "        console_prefix += f\"[{agent_name}] \"\n",
    "    print(f\"{console_prefix}{message}\")\n",
    "\n",
    "def display_report(report, title=\"Research Report\"):\n",
    "    \"\"\"Display a formatted research report in the notebook.\"\"\"\n",
    "    display(Markdown(f\"## {title}\"))\n",
    "    display(Markdown(report))\n",
    "    \n",
    "    # Also log to console for backup\n",
    "    print(f\"\\n{'='*50}\\n{title}\\n{'='*50}\\n{report}\\n{'='*50}\\n\")\n",
    "\n",
    "def display_separator(title=None):\n",
    "    \"\"\"Display a visual separator in the logs.\"\"\"\n",
    "    if title:\n",
    "        display_log(f\"{'='*20} {title} {'='*20}\", message_type=\"system\", include_timestamp=False)\n",
    "    else:\n",
    "        display_log(f\"{'='*50}\", message_type=\"system\", include_timestamp=False)\n",
    "\n",
    "def save_research_results(results, filename=None):\n",
    "    \"\"\"Save research results to a JSON file.\"\"\"\n",
    "    if filename is None:\n",
    "        words = results[\"question\"].split()[:5]\n",
    "        safe_words = [word.lower() for word in words if word.isalnum()]\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"research_{'_'.join(safe_words)}_{timestamp}.json\"\n",
    "    \n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    display_log(f\"Research results saved to {filename}\", message_type=\"system\")\n",
    "    \n",
    "    # Log the content that was saved\n",
    "    display_log(f\"Report saved ({len(results['report'])} chars, {len(results['steps'])} steps)\", message_type=\"debug\")\n",
    "    if not results[\"report\"]:\n",
    "        display_log(f\"WARNING: Empty report saved to file!\", message_type=\"warning\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# Create a function to generate specific research queries\n",
    "def generate_research_queries(topic: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate specific research queries for a topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: The main research topic or question\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with recommended search queries\n",
    "    \"\"\"\n",
    "    display_log(f\"Generating research queries for: {topic}\", message_type=\"system\")\n",
    "    \n",
    "    # Return a template structure\n",
    "    return {\n",
    "        \"status\": \"generated\",\n",
    "        \"message\": \"Please use these query templates with the search_agent tool.\",\n",
    "        \"instructions\": \"\"\"\n",
    "        REQUIRED STEPS:\n",
    "        1. For each query template below, replace it with a specific, detailed search query\n",
    "        2. Call search_agent(query=\"your specific query\") for EACH of the 5 queries\n",
    "        3. You MUST make exactly 5 separate search calls\n",
    "        \n",
    "        Replace each template with a specific query related to the topic.\n",
    "        \"\"\",\n",
    "        \"query_templates\": [\n",
    "            f\"basic explanation of {topic} for children\",\n",
    "            f\"how does {topic} work simple explanation\",\n",
    "            f\"parts of {topic} and their functions\",\n",
    "            f\"{topic} simple diagram explanation\",\n",
    "            f\"{topic} example of how it's used\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Function to finalize a research report\n",
    "def finalize_report(research_findings: str, target_audience: str) -> dict:\n",
    "    \"\"\"\n",
    "    Finalize and format a research report.\n",
    "    \n",
    "    Args:\n",
    "        research_findings: The compiled research findings\n",
    "        target_audience: Who the report is intended for (e.g., \"children\", \"adults\", \"experts\")\n",
    "        \n",
    "    Returns:\n",
    "        dict: Report formatting instructions\n",
    "    \"\"\"\n",
    "    if not research_findings or len(research_findings.strip()) < 100:\n",
    "        display_log(f\"WARNING: Research findings too short ({len(research_findings) if research_findings else 0} chars)\", message_type=\"warning\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": \"Research findings are too short. Please provide more comprehensive findings.\"\n",
    "        }\n",
    "    \n",
    "    display_log(f\"Finalizing report for {target_audience} audience\", message_type=\"system\")\n",
    "    \n",
    "    # Return report formatting template\n",
    "    return {\n",
    "        \"status\": \"ready_to_finalize\",\n",
    "        \"message\": \"Please format your final report according to these instructions.\",\n",
    "        \"instructions\": f\"\"\"\n",
    "        FINAL REPORT FORMAT:\n",
    "        \n",
    "        Your report MUST begin with: \"### FINAL RESEARCH REPORT ###\"\n",
    "        \n",
    "        Structure your report with these sections:\n",
    "        1. Introduction - What is {research_findings[:30]}... and why it's interesting\n",
    "        2. How It Works - Simple explanation tailored for {target_audience}\n",
    "        3. Key Parts - The main components and what they do\n",
    "        4. Real World Examples - How it's used in everyday situations\n",
    "        5. Fun Facts - Interesting tidbits discovered in your research\n",
    "        \n",
    "        Your report MUST end with: \"### END OF REPORT ###\"\n",
    "        \n",
    "        Important:\n",
    "        - Include citations to sources throughout\n",
    "        - Use language appropriate for {target_audience}\n",
    "        - Include bullet points and simple explanations\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "# Application constants\n",
    "APP_NAME = \"deep_research_app\"\n",
    "USER_ID = \"user1234\"\n",
    "SESSION_ID = f\"session_{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "\n",
    "# 1. Create the Search Agent with direct access to the google_search tool\n",
    "search_agent = LlmAgent(\n",
    "    name=\"search_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"Agent specialized in web search and information retrieval\",\n",
    "    instruction=\"\"\"\n",
    "    You are a specialized web search agent that performs targeted research.\n",
    "    \n",
    "    PROCESS:\n",
    "    1. You will receive a specific search query from the research manager\n",
    "    2. Execute the search using the google_search tool with EXACTLY that query\n",
    "    3. Analyze the search results and extract relevant information\n",
    "    4. Format your response in a clear, structured way\n",
    "    \n",
    "    RESPONSE FORMAT:\n",
    "    Always structure your response as follows:\n",
    "    \n",
    "    === SEARCH RESULTS ===\n",
    "    QUERY: [the exact query you searched for]\n",
    "    \n",
    "    SUMMARY:\n",
    "    [2-3 sentence overview of what you found]\n",
    "    \n",
    "    KEY FINDINGS:\n",
    "    • [First important point with source]\n",
    "    • [Second important point with source]\n",
    "    • [Continue with additional points]\n",
    "    \n",
    "    SOURCES:\n",
    "    1. [Name/title of source]: [Brief description]\n",
    "    2. [Name/title of source]: [Brief description]\n",
    "    \n",
    "    === END RESULTS ===\n",
    "    \n",
    "    IMPORTANT:\n",
    "    - You MUST use the google_search tool with the EXACT query provided\n",
    "    - If the query is empty or unclear, ask for clarification\n",
    "    - Always cite sources for your information\n",
    "    - Focus on being informative and complete\n",
    "    \"\"\",\n",
    "    tools=[google_search]  # Only the search agent has access to google_search\n",
    ")\n",
    "\n",
    "# 2. Create the Agent Tool wrapper for the search agent\n",
    "search_agent_tool = AgentTool(\n",
    "    agent=search_agent\n",
    ")\n",
    "\n",
    "# 3. Create the Research Manager Agent\n",
    "manager_agent = LlmAgent(\n",
    "    name=\"research_manager\",\n",
    "    model=\"gemini-2.5-flash-preview-04-17\",\n",
    "    description=\"Manager agent that coordinates deep research processes\",\n",
    "    instruction=\"\"\"\n",
    "    You are a research manager responsible for thoroughly researching topics and creating comprehensive reports.\n",
    "    \n",
    "    MANDATORY WORKFLOW - You MUST follow these steps in order:\n",
    "    \n",
    "    1. PLANNING PHASE:\n",
    "       - When given a research topic, call generate_research_queries(topic)\n",
    "       - Use the provided query templates to create 5 SPECIFIC search queries\n",
    "    \n",
    "    2. RESEARCH PHASE:\n",
    "       - For EACH of your 5 queries, call: search_agent(query=\"your specific query\")\n",
    "       - Make exactly 5 separate search_agent calls with different queries\n",
    "       - Review each set of results before making the next search\n",
    "    \n",
    "    3. SYNTHESIS PHASE:\n",
    "       - Compile and synthesize all the information gathered\n",
    "       - Call finalize_report() with your compiled findings and the target audience\n",
    "    \n",
    "    4. REPORT CREATION PHASE:\n",
    "       - Create your final report following the provided format EXACTLY\n",
    "       - Your report MUST begin with \"### FINAL RESEARCH REPORT ###\"\n",
    "       - Your report MUST end with \"### END OF REPORT ###\"\n",
    "       - Include all key information with proper citations\n",
    "    \n",
    "    CRITICAL RULES:\n",
    "    - You CANNOT answer any question directly without completing ALL research steps\n",
    "    - ALL of your search queries must be specific and detailed\n",
    "    - Your final report MUST follow the exact format specified\n",
    "    - You MUST make exactly 5 distinct search_agent calls\n",
    "    \n",
    "    Remember that your goal is to create a comprehensive, accurate report based on actual search results, not your pre-existing knowledge.\n",
    "    \"\"\",\n",
    "    tools=[\n",
    "        FunctionTool(generate_research_queries),\n",
    "        FunctionTool(finalize_report),\n",
    "        search_agent_tool\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set up session service and runner\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(\n",
    "    agent=manager_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service\n",
    ")\n",
    "session = session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "\n",
    "# Main function to run deep research\n",
    "def run_deep_research(research_question, audience=\"children\"):\n",
    "    \"\"\"\n",
    "    Execute deep research on a given question using the manager-search agent system.\n",
    "    \n",
    "    Args:\n",
    "        research_question: The main research question or topic\n",
    "        audience: Target audience for the report (default: \"children\")\n",
    "        \n",
    "    Returns:\n",
    "        dict: Research results including steps and final report\n",
    "    \"\"\"\n",
    "    display_separator(\"STARTING RESEARCH\")\n",
    "    display_log(f\"Research topic: {research_question}\", message_type=\"info\")\n",
    "    display_log(f\"Target audience: {audience}\", message_type=\"info\")\n",
    "    \n",
    "    # Modify the question to explicitly require following the process\n",
    "    enhanced_prompt = f\"\"\"\n",
    "    RESEARCH ASSIGNMENT:\n",
    "    \n",
    "    Topic: {research_question}\n",
    "    Target audience: {audience}\n",
    "    \n",
    "    Please research this topic thoroughly by following your mandatory workflow EXACTLY:\n",
    "    1. Generate specific research queries\n",
    "    2. Perform 5 separate searches using the search_agent\n",
    "    3. Synthesize the information\n",
    "    4. Create a final report with proper format and citations\n",
    "    \n",
    "    Critically important: You MUST follow ALL steps in order. You CANNOT answer based on your own knowledge.\n",
    "    Your report MUST begin with \"### FINAL RESEARCH REPORT ###\" and end with \"### END OF REPORT ###\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create content object with research question\n",
    "    content = types.Content(\n",
    "        role='user',\n",
    "        parts=[types.Part(text=enhanced_prompt)]\n",
    "    )\n",
    "    \n",
    "    # Track research process and results\n",
    "    research_steps = []\n",
    "    final_report = \"\"\n",
    "    search_count = 0\n",
    "    large_response = \"\"\n",
    "    \n",
    "    # Create progress bar\n",
    "    progress = tqdm(desc=\"Research in progress\", unit=\"steps\")\n",
    "    \n",
    "    try:\n",
    "        # Process the research through the runner\n",
    "        for event in runner.run(\n",
    "            user_id=USER_ID,\n",
    "            session_id=SESSION_ID,\n",
    "            new_message=content\n",
    "        ):\n",
    "            # Handle events based on type\n",
    "            if hasattr(event, 'content') and event.content:\n",
    "                for part in event.content.parts:\n",
    "                    # Track function calls\n",
    "                    if hasattr(part, 'function_call') and part.function_call:\n",
    "                        function_name = part.function_call.name\n",
    "                        \n",
    "                        if function_name == \"search_agent\":\n",
    "                            # Extract the query parameter from the function call args\n",
    "                            args = part.function_call.args if hasattr(part.function_call, 'args') else {}\n",
    "                            search_query = args.get('query', '')\n",
    "                            \n",
    "                            if search_query and len(search_query.strip()) > 0:\n",
    "                                search_count += 1\n",
    "                                step = {\n",
    "                                    \"type\": \"search\",\n",
    "                                    \"query\": search_query,\n",
    "                                    \"agent\": event.author,\n",
    "                                    \"timestamp\": format_time()\n",
    "                                }\n",
    "                                research_steps.append(step)\n",
    "                                display_log(f\"Search #{search_count}: {search_query}\", event.author, \"search\")\n",
    "                            else:\n",
    "                                display_log(f\"WARNING: Empty search query detected\", event.author, \"warning\")\n",
    "                        \n",
    "                        elif function_name == \"generate_research_queries\":\n",
    "                            # Track when the generate_research_queries function is called\n",
    "                            args = part.function_call.args if hasattr(part.function_call, 'args') else {}\n",
    "                            topic = args.get('topic', '')\n",
    "                            display_log(f\"Generating queries for: {topic}\", event.author, \"manager\")\n",
    "                        \n",
    "                        elif function_name == \"finalize_report\":\n",
    "                            # Track when the finalize_report function is called\n",
    "                            args = part.function_call.args if hasattr(part.function_call, 'args') else {}\n",
    "                            findings_preview = (args.get('research_findings', '') or '')[:50] + \"...\"\n",
    "                            target = args.get('target_audience', '')\n",
    "                            display_log(f\"Finalizing report for {target} audience: {findings_preview}\", event.author, \"manager\")\n",
    "                        \n",
    "                        elif function_name == \"google_search\":\n",
    "                            # This shows when the search agent actually uses google_search\n",
    "                            args = part.function_call.args if hasattr(part.function_call, 'args') else {}\n",
    "                            search_query = args.get('query', '')\n",
    "                            \n",
    "                            if search_query and len(search_query.strip()) > 0:\n",
    "                                display_log(f\"Executing Google search for: {search_query}\", \"search_agent\", \"search\")\n",
    "                            else:\n",
    "                                display_log(f\"WARNING: Empty Google search query\", \"search_agent\", \"warning\")\n",
    "                        \n",
    "                        else:\n",
    "                            display_log(f\"Function call: {function_name}\", event.author, \"debug\")\n",
    "                        \n",
    "                        progress.update(1)\n",
    "                    \n",
    "                    # Track function responses\n",
    "                    if hasattr(part, 'function_response') and part.function_response:\n",
    "                        function_name = part.function_response.name\n",
    "                        \n",
    "                        if function_name == \"search_agent\":\n",
    "                            display_log(f\"Received search results (search #{search_count})\", event.author, \"result\")\n",
    "                        elif function_name == \"google_search\":\n",
    "                            display_log(f\"Google search completed\", \"search_agent\", \"result\")\n",
    "                        elif function_name == \"generate_research_queries\":\n",
    "                            display_log(f\"Research queries generated\", event.author, \"result\")\n",
    "                        elif function_name == \"finalize_report\":\n",
    "                            display_log(f\"Report format provided\", event.author, \"result\")\n",
    "                        else:\n",
    "                            display_log(f\"Function response: {function_name}\", event.author, \"debug\")\n",
    "                    \n",
    "                    # Track text responses\n",
    "                    if hasattr(part, 'text') and part.text:\n",
    "                        text = part.text\n",
    "                        \n",
    "                        # Check for report markers\n",
    "                        if \"### FINAL RESEARCH REPORT ###\" in text and \"### END OF REPORT ###\" in text:\n",
    "                            # Extract everything between the markers\n",
    "                            start_marker = \"### FINAL RESEARCH REPORT ###\"\n",
    "                            end_marker = \"### END OF REPORT ###\"\n",
    "                            start_index = text.find(start_marker)\n",
    "                            end_index = text.find(end_marker) + len(end_marker)\n",
    "                            \n",
    "                            if start_index >= 0 and end_index > start_index:\n",
    "                                final_report = text[start_index:end_index]\n",
    "                                display_log(f\"Final report detected ({len(final_report)} chars)\", event.author, \"result\")\n",
    "                            else:\n",
    "                                display_log(f\"WARNING: Report markers found but couldn't extract report properly\", event.author, \"warning\")\n",
    "                        \n",
    "                        # Also track the largest response as a backup\n",
    "                        if len(text) > len(large_response):\n",
    "                            large_response = text\n",
    "                            if len(text) > 500:\n",
    "                                display_log(f\"Substantial response detected ({len(text)} chars)\", event.author, \"debug\")\n",
    "                        \n",
    "                        # Log the message with preview\n",
    "                        if event.author == \"research_manager\":\n",
    "                            if len(text) > 100:\n",
    "                                display_log(f\"Message: {text[:100]}...\", event.author, \"manager\")\n",
    "                            else:\n",
    "                                display_log(f\"Message: {text}\", event.author, \"manager\")\n",
    "                        elif event.author == \"search_agent\":\n",
    "                            if len(text) > 100:\n",
    "                                display_log(f\"Message: {text[:100]}...\", event.author, \"search_agent\")\n",
    "                            else:\n",
    "                                display_log(f\"Message: {text}\", event.author, \"search_agent\")\n",
    "        \n",
    "        progress.close()\n",
    "        \n",
    "        # If no final report with correct markers was found, use backup strategies\n",
    "        if not final_report:\n",
    "            display_log(\"No properly formatted report found. Checking for alternatives...\", message_type=\"warning\")\n",
    "            \n",
    "            # Check if large_response contains substantial content that might be a report\n",
    "            if large_response and len(large_response) > 500:\n",
    "                display_log(f\"Using largest response as report ({len(large_response)} chars)\", message_type=\"system\")\n",
    "                final_report = large_response\n",
    "            else:\n",
    "                display_log(\"No substantial response found either. Checking full history...\", message_type=\"warning\")\n",
    "                \n",
    "                # As a last resort, scan through the entire conversation history\n",
    "                history_events = list(runner.get_history(USER_ID, SESSION_ID))\n",
    "                \n",
    "                display_log(f\"Scanning {len(history_events)} events in history...\", message_type=\"debug\")\n",
    "                \n",
    "                # Look for any substantial text from the manager\n",
    "                for event in reversed(history_events):\n",
    "                    if (hasattr(event, 'author') and event.author == \"research_manager\" and \n",
    "                        hasattr(event, 'content') and event.content):\n",
    "                        \n",
    "                        for part in event.content.parts:\n",
    "                            if (hasattr(part, 'text') and part.text and \n",
    "                                len(part.text) > 300):\n",
    "                                \n",
    "                                if not final_report or len(part.text) > len(final_report):\n",
    "                                    final_report = part.text\n",
    "                                    display_log(f\"Found potential report in history ({len(final_report)} chars)\", message_type=\"system\")\n",
    "                \n",
    "                if not final_report:\n",
    "                    display_log(\"CRITICAL: Could not find any suitable report content!\", message_type=\"error\")\n",
    "        \n",
    "        # Prepare results dict\n",
    "        results = {\n",
    "            \"question\": research_question,\n",
    "            \"steps\": research_steps,\n",
    "            \"report\": final_report,\n",
    "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"search_count\": search_count,\n",
    "            \"audience\": audience\n",
    "        }\n",
    "        \n",
    "        # Display the final report\n",
    "        if final_report:\n",
    "            display_separator(\"FINAL REPORT\")\n",
    "            display_report(final_report)\n",
    "        else:\n",
    "            display_log(\"No final report was generated\", message_type=\"error\")\n",
    "            \n",
    "            # Print debug info\n",
    "            display_separator(\"DEBUG INFO\")\n",
    "            display_log(f\"Total search calls: {search_count}\", message_type=\"debug\")\n",
    "            display_log(f\"Total research steps: {len(research_steps)}\", message_type=\"debug\")\n",
    "            display_log(f\"Largest response size: {len(large_response)} chars\", message_type=\"debug\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        display_log(f\"ERROR: {str(e)}\", message_type=\"error\")\n",
    "        display_log(traceback.format_exc(), message_type=\"error\")\n",
    "        \n",
    "        # Try to salvage what we can\n",
    "        results = {\n",
    "            \"question\": research_question,\n",
    "            \"steps\": research_steps,\n",
    "            \"report\": final_report or large_response or \"Error occurred during research\",\n",
    "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "research_question = \"From the perspective of a 5 year old, can you explain how excavators work?\"\n",
    "results = run_deep_research(research_question, audience=\"5 year old children\")\n",
    "\n",
    "# Save results to file\n",
    "filename = save_research_results(results)\n",
    "display_log(f\"Research completed and saved to {filename}\", message_type=\"info\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56324a01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SessionService' from 'google.adk.sessions' (c:\\Users\\xbox3\\miniforge-pypy3\\envs\\py311env\\Lib\\site-packages\\google\\adk\\sessions\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LlmAgent, Agent\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Runner\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msessions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SessionService\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01madk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m google_search\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m types\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SessionService' from 'google.adk.sessions' (c:\\Users\\xbox3\\miniforge-pypy3\\envs\\py311env\\Lib\\site-packages\\google\\adk\\sessions\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import datetime\n",
    "import logging\n",
    "from typing import Dict, List, Optional\n",
    "from google.adk.agents import LlmAgent, Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import SessionService\n",
    "from google.adk.tools import google_search\n",
    "from google.genai import types\n",
    "from google.api_core import exceptions\n",
    "from slugify import slugify\n",
    "import asyncio\n",
    "\n",
    "# Hypothetical arXiv search tool (replace with actual implementation if available)\n",
    "async def arxiv_search(query: str) -> Dict:\n",
    "    \"\"\"Mock arXiv search tool for demonstration.\"\"\"\n",
    "    return {\"results\": [{\"title\": f\"Mock arXiv paper on {query}\", \"url\": \"http://arxiv.org/mock\"}]}\n",
    "\n",
    "# Configuration (replace with your settings module)\n",
    "class Settings:\n",
    "    GEMINI_GENERATE_KEY = os.getenv(\"GEMINI_GENERATE_KEY\", \"your-api-key-here\")\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "# Set up Gemini API key\n",
    "os.environ[\"GOOGLE_API_KEY\"] = settings.GEMINI_GENERATE_KEY\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "\n",
    "# Custom file-based session service for persistence (simplified for example)\n",
    "class FileSessionService(SessionService):\n",
    "    def __init__(self, storage_path: str = \"sessions\"):\n",
    "        self.storage_path = storage_path\n",
    "        os.makedirs(storage_path, exist_ok=True)\n",
    "    \n",
    "    def create_session(self, app_name: str, user_id: str, session_id: str) -> Dict:\n",
    "        session_data = {\"app_name\": app_name, \"user_id\": user_id, \"session_id\": session_id, \"data\": {}}\n",
    "        file_path = os.path.join(self.storage_path, f\"{session_id}.json\")\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(session_data, f)\n",
    "        return session_data\n",
    "    \n",
    "    def get_session(self, session_id: str) -> Optional[Dict]:\n",
    "        file_path = os.path.join(self.storage_path, f\"{session_id}.json\")\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                return json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            return None\n",
    "\n",
    "# Configure logging for both notebook and non-notebook environments\n",
    "class NotebookFormatter(logging.Formatter):\n",
    "    COLORS = {\n",
    "        \"INFO\": \"#3498db\",  # Blue\n",
    "        \"SEARCH\": \"#e67e22\",  # Orange\n",
    "        \"RESULT\": \"#2ecc71\",  # Green\n",
    "        \"ERROR\": \"#e74c3c\",  # Red\n",
    "        \"MANAGER\": \"#9b59b6\",  # Purple\n",
    "        \"SEARCH_AGENT\": \"#f1c40f\"  # Yellow\n",
    "    }\n",
    "    \n",
    "    def __init__(self, is_notebook: bool = False):\n",
    "        self.is_notebook = is_notebook\n",
    "        super().__init__()\n",
    "    \n",
    "    def format(self, record):\n",
    "        level = record.levelname if record.levelname != \"SEARCH\" else \"SEARCH\"\n",
    "        message = record.getMessage()\n",
    "        timestamp = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "        prefix = f\"[{timestamp}]\"\n",
    "        if hasattr(record, \"agent_name\") and record.agent_name:\n",
    "            prefix += f\" [{record.agent_name}]\"\n",
    "        \n",
    "        if self.is_notebook:\n",
    "            color = self.COLORS.get(level, \"#3498db\")\n",
    "            return f\"<div style='margin-bottom: 10px;'><span style='color: {color}; font-weight: bold;'>{prefix}</span> {message}</div>\"\n",
    "        return f\"{prefix} {level}: {message}\"\n",
    "\n",
    "def setup_logging(is_notebook: bool = False) -> logging.Logger:\n",
    "    logger = logging.getLogger(\"DeepResearch\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setFormatter(NotebookFormatter(is_notebook=is_notebook))\n",
    "    logger.handlers = [handler]\n",
    "    return logger\n",
    "\n",
    "# Helper functions\n",
    "def display_report(report: str, title: str = \"Research Report\", is_notebook: bool = False, logger: logging.Logger = None):\n",
    "    \"\"\"Display a formatted research report.\"\"\"\n",
    "    if is_notebook:\n",
    "        from IPython.display import display, Markdown\n",
    "        display(Markdown(f\"## {title}\"))\n",
    "        display(Markdown(report))\n",
    "    else:\n",
    "        logger.info(f\"{title}:\\n{report}\")\n",
    "\n",
    "def save_research_results(results: Dict, filename: Optional[str] = None, logger: logging.Logger = None) -> str:\n",
    "    \"\"\"Save research results to a JSON file.\"\"\"\n",
    "    if filename is None:\n",
    "        safe_name = slugify(results[\"question\"][:50], separator=\"_\")\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"research_{safe_name}_{timestamp}.json\"\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        logger.info(f\"Research results saved to {filename}\")\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save results: {str(e)}\")\n",
    "        return \"\"\n",
    "\n",
    "# Application constants\n",
    "APP_NAME = \"deep_research_app\"\n",
    "USER_ID = f\"user_{uuid.uuid4()}\"  # Dynamic user ID\n",
    "SESSION_ID = f\"session_{uuid.uuid4()}\"  # Dynamic session ID\n",
    "\n",
    "# Create agents\n",
    "def create_agents() -> tuple[LlmAgent, LlmAgent]:\n",
    "    search_agent = LlmAgent(\n",
    "        name=\"web_search_agent\",\n",
    "        model=\"gemini-1.5-flash\",  # Lightweight model for search\n",
    "        description=\"Agent specialized in web and academic search\",\n",
    "        instruction=\"\"\"\n",
    "        You are a web search agent. Your tasks:\n",
    "        1. Receive search queries from the research manager.\n",
    "        2. Execute searches using available tools (e.g., Google, arXiv).\n",
    "        3. Summarize relevant information in a concise, factual format.\n",
    "        4. Include source URLs or identifiers for all information.\n",
    "        Return responses as JSON with fields: summary, sources.\n",
    "        \"\"\",\n",
    "        tools=[google_search, arxiv_search]\n",
    "    )\n",
    "    \n",
    "    manager_agent = LlmAgent(\n",
    "        name=\"research_manager\",\n",
    "        model=\"gemini-1.5-pro\",  # Stronger model for coordination\n",
    "        description=\"Manager agent coordinating deep research\",\n",
    "        instruction=\"\"\"\n",
    "        You are a research manager agent. For each research question:\n",
    "        1. Create a plan with 3-5 specific search queries.\n",
    "        2. Delegate queries to the web search agent.\n",
    "        3. Synthesize results into a report with sections: Introduction, Findings, Conclusion, Citations.\n",
    "        4. Identify knowledge gaps and request additional searches if needed.\n",
    "        Return the final report as a markdown-formatted string with clear citations.\n",
    "        \"\"\",\n",
    "        sub_agents=[search_agent]\n",
    "    )\n",
    "    \n",
    "    return search_agent, manager_agent\n",
    "\n",
    "# Main research function\n",
    "async def run_deep_research(\n",
    "    research_question: str,\n",
    "    logger: logging.Logger,\n",
    "    is_notebook: bool = False,\n",
    "    session_service: Optional[SessionService] = None\n",
    ") -> Dict:\n",
    "    \"\"\"Execute deep research on a given question.\"\"\"\n",
    "    logger.info(f\"Starting deep research: {research_question}\")\n",
    "    \n",
    "    # Initialize session and runner\n",
    "    session_service = session_service or FileSessionService()\n",
    "    search_agent, manager_agent = create_agents()\n",
    "    runner = Runner(\n",
    "        agent=manager_agent,\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service\n",
    "    )\n",
    "    session = session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID)\n",
    "    \n",
    "    # Create content object\n",
    "    content = types.Content(role='user', parts=[types.Part(text=research_question)])\n",
    "    \n",
    "    # Track research process\n",
    "    research_steps = []\n",
    "    manager_outputs = []\n",
    "    final_report = \"\"\n",
    "    \n",
    "    try:\n",
    "        if is_notebook:\n",
    "            from tqdm.notebook import tqdm\n",
    "        else:\n",
    "            from tqdm import tqdm\n",
    "        \n",
    "        # Use indeterminate progress bar\n",
    "        with tqdm(desc=\"Research in progress\", total=None) as progress:\n",
    "            for event in runner.run(user_id=USER_ID, session_id=SESSION_ID, new_message=content):\n",
    "                if not hasattr(event, 'content') or not event.content:\n",
    "                    logger.warning(\"Empty event received\")\n",
    "                    continue\n",
    "                \n",
    "                for part in event.content.parts:\n",
    "                    if hasattr(part, 'function_call') and part.function_call:\n",
    "                        search_query = part.function_call.args.get('query', '')\n",
    "                        step = {\n",
    "                            \"type\": \"search\",\n",
    "                            \"query\": search_query,\n",
    "                            \"agent\": event.author,\n",
    "                            \"timestamp\": datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "                        }\n",
    "                        research_steps.append(step)\n",
    "                        logger.info(f\"Searching for: {search_query}\", extra={\"agent_name\": event.author, \"level\": \"SEARCH\"})\n",
    "                        progress.update()\n",
    "                    \n",
    "                    if hasattr(part, 'function_response') and part.function_response:\n",
    "                        logger.info(f\"Received search results\", extra={\"agent_name\": event.author, \"level\": \"RESULT\"})\n",
    "                    \n",
    "                    if hasattr(part, 'text') and part.text and event.author == \"research_manager\":\n",
    "                        manager_outputs.append(part.text)\n",
    "                        if \"Final Report\" in part.text or any(k in part.text.lower() for k in [\"conclusion\", \"summary\", \"findings\"]):\n",
    "                            final_report = part.text\n",
    "                            logger.info(f\"Research report generated\", extra={\"agent_name\": event.author, \"level\": \"MANAGER\"})\n",
    "        \n",
    "        # Fallback: combine manager outputs if no explicit report\n",
    "        if not final_report and manager_outputs:\n",
    "            final_report = \"\\n\".join(manager_outputs)\n",
    "            logger.warning(\"No explicit report found; combined manager outputs\")\n",
    "        \n",
    "        if not final_report:\n",
    "            logger.error(\"No final report generated\")\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            \"question\": research_question,\n",
    "            \"steps\": research_steps,\n",
    "            \"report\": final_report,\n",
    "            \"timestamp\": datetime.datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # Display and save results\n",
    "        if final_report:\n",
    "            display_report(final_report, is_notebook=is_notebook, logger=logger)\n",
    "        save_research_results(results, logger=logger)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except exceptions.GoogleAPIError as e:\n",
    "        logger.error(f\"API error during research: {str(e)}\")\n",
    "        return {\"question\": research_question, \"error\": str(e)}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error: {str(e)}\")\n",
    "        return {\"question\": research_question, \"error\": str(e)}\n",
    "\n",
    "\n",
    "research_question = \"What are the latest advancements in quantum computing and their potential applications?\"\n",
    "results = asyncio.run(run_deep_research(research_question, logger=logger, is_notebook=is_notebook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30988954",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simplified AI Interview System using Google's Agent Development Kit (ADK)\n",
    "\n",
    "This system creates a natural conversation between two AI agents:\n",
    "- Expert Agent: Provides expertise on a specified topic\n",
    "- Interviewer Agent: Asks questions about the topic\n",
    "\n",
    "The conversation is saved as both text and MP3 audio files.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import argparse\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "\n",
    "# Google Agent Development Kit and Gemini imports\n",
    "import google.generativeai as genai\n",
    "from google.adk import LlmAgent, Runner, InMemorySessionService\n",
    "from google.generativeai import types\n",
    "\n",
    "# Audio generation and processing\n",
    "from google.cloud import texttospeech\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration constants\n",
    "APP_NAME = \"interview_simulation\"\n",
    "USER_ID = \"user_1\"\n",
    "\n",
    "\n",
    "def setup_interview_agents(topic: str):\n",
    "    \"\"\"Set up the expert and interviewer agents using ADK.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic for the interview\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (expert_agent, interviewer_agent)\n",
    "    \"\"\"\n",
    "    # Create the Expert Agent\n",
    "    expert_agent = LlmAgent(\n",
    "        name=\"expert\",\n",
    "        model=\"gemini-2.0-flash-exp\",  # Using Gemini Flash for quick responses\n",
    "        description=f\"Expert on {topic} providing authoritative but accessible information\",\n",
    "        instruction=f\"\"\"\n",
    "        You are an expert on {topic} with deep knowledge and experience.\n",
    "        \n",
    "        Your role:\n",
    "        - Provide factual, informative responses about {topic}\n",
    "        - Share expert insights and perspectives based on your specialized knowledge\n",
    "        - Present complex information in an accessible, conversational manner\n",
    "        - Maintain a confident but approachable tone\n",
    "        \n",
    "        Guidelines:\n",
    "        - Keep your responses concise and focused (2-4 sentences per response)\n",
    "        - Use a conversational tone suitable for audio content\n",
    "        - Avoid jargon unless necessary, and explain technical terms when used\n",
    "        - Speak as if you were being interviewed for a podcast or radio show\n",
    "        \n",
    "        Remember, your responses will be converted to audio, so maintain a natural \n",
    "        conversational flow.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Define the ask_expert tool\n",
    "    ask_expert_tool = {\n",
    "        \"name\": \"ask_expert\",\n",
    "        \"description\": f\"Ask the expert a question about {topic}\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The question to ask the expert\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"question\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create the Interviewer Agent\n",
    "    interviewer_agent = LlmAgent(\n",
    "        name=\"interviewer\",\n",
    "        model=\"gemini-2.0-flash-exp\",  # Using Gemini Flash for quick responses\n",
    "        description=f\"Professional interviewer conducting an interview about {topic}\",\n",
    "        instruction=f\"\"\"\n",
    "        You are a professional interviewer conducting an interview about {topic}.\n",
    "        \n",
    "        Your role:\n",
    "        - Ask thoughtful, engaging questions about {topic}\n",
    "        - Guide the conversation to cover important aspects of the topic\n",
    "        - Follow up on interesting points the expert mentions\n",
    "        - Represent the curiosity of your audience\n",
    "        \n",
    "        Conversation structure:\n",
    "        1. Start with an introduction and an opening question\n",
    "        2. Ask follow-up questions based on the expert's responses\n",
    "        3. Explore different aspects of {topic}\n",
    "        4. Conclude with a final question about future implications or advice\n",
    "        \n",
    "        Guidelines:\n",
    "        - Keep questions concise and clear (1-2 sentences)\n",
    "        - Maintain a conversational tone suitable for audio\n",
    "        - Don't ask multiple questions at once\n",
    "        - Listen to the expert's responses and reference them in follow-ups\n",
    "        \n",
    "        When you need to ask a question to the expert, call the 'ask_expert' function with your question.\n",
    "        \"\"\",\n",
    "        tools=[ask_expert_tool],\n",
    "        sub_agents=[expert_agent]  # The interviewer can delegate to the expert\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Agents set up for topic: {topic}\")\n",
    "    return expert_agent, interviewer_agent\n",
    "\n",
    "\n",
    "def text_to_speech(text: str, voice_config: Dict[str, Any]) -> AudioSegment:\n",
    "    \"\"\"Convert text to speech using Google's Text-to-Speech API.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to convert to speech\n",
    "        voice_config: Configuration for the voice (gender, language, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        Audio segment with the synthesized speech\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = texttospeech.TextToSpeechClient()\n",
    "        \n",
    "        synthesis_input = texttospeech.SynthesisInput(text=text)\n",
    "        \n",
    "        # Default to NEUTRAL gender if not specified\n",
    "        gender = voice_config.get(\"gender\", texttospeech.SsmlVoiceGender.NEUTRAL)\n",
    "        \n",
    "        voice = texttospeech.VoiceSelectionParams(\n",
    "            language_code=voice_config.get(\"language_code\", \"en-US\"),\n",
    "            ssml_gender=gender,\n",
    "            name=voice_config.get(\"name\", None)\n",
    "        )\n",
    "        \n",
    "        audio_config = texttospeech.AudioConfig(\n",
    "            audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "            speaking_rate=voice_config.get(\"speaking_rate\", 1.0),\n",
    "            pitch=voice_config.get(\"pitch\", 0.0)\n",
    "        )\n",
    "        \n",
    "        response = client.synthesize_speech(\n",
    "            input=synthesis_input, voice=voice, audio_config=audio_config\n",
    "        )\n",
    "        \n",
    "        # Convert response to AudioSegment\n",
    "        audio_data = BytesIO(response.audio_content)\n",
    "        audio_segment = AudioSegment.from_mp3(audio_data)\n",
    "        \n",
    "        return audio_segment\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in text-to-speech conversion: {e}\")\n",
    "        # Return silent audio as fallback\n",
    "        return AudioSegment.silent(duration=500)\n",
    "\n",
    "\n",
    "def process_event(event, conversation, audio_segments, interviewer_voice, expert_voice):\n",
    "    \"\"\"Process a single event from the ADK runner.\n",
    "    \n",
    "    Args:\n",
    "        event: The event to process\n",
    "        conversation: List to store conversation entries\n",
    "        audio_segments: List to store audio segments\n",
    "        interviewer_voice: Voice configuration for the interviewer\n",
    "        expert_voice: Voice configuration for the expert\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if event.type == \"text\" and event.text.role == \"assistant\":\n",
    "            # Interviewer's statement/question\n",
    "            interviewer_text = event.text.text\n",
    "            if interviewer_text.strip():\n",
    "                logger.info(\"Processing interviewer text\")\n",
    "                conversation.append({\n",
    "                    \"speaker\": \"Interviewer\",\n",
    "                    \"text\": interviewer_text\n",
    "                })\n",
    "                # Convert to audio\n",
    "                interviewer_audio = text_to_speech(interviewer_text, interviewer_voice)\n",
    "                audio_segments.append(interviewer_audio)\n",
    "                \n",
    "        elif event.type == \"function_call\" and event.function_call.name == \"ask_expert\":\n",
    "            # Question for the expert (just log it, no need to store)\n",
    "            question = event.function_call.args.get(\"question\", \"\")\n",
    "            logger.info(f\"Expert asked: {question[:50]}...\")\n",
    "            \n",
    "        elif event.type == \"function_response\" and event.function_response.name == \"ask_expert\":\n",
    "            # Expert's response\n",
    "            expert_text = event.function_response.content\n",
    "            if expert_text.strip():\n",
    "                logger.info(\"Processing expert response\")\n",
    "                conversation.append({\n",
    "                    \"speaker\": \"Expert\",\n",
    "                    \"text\": expert_text\n",
    "                })\n",
    "                # Convert to audio\n",
    "                expert_audio = text_to_speech(expert_text, expert_voice)\n",
    "                audio_segments.append(expert_audio)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing event: {e}\")\n",
    "\n",
    "\n",
    "def save_interview_results(topic, session_id, conversation, audio_segments):\n",
    "    \"\"\"Save the interview results to files.\n",
    "    \n",
    "    Args:\n",
    "        topic: The interview topic\n",
    "        session_id: The session ID\n",
    "        conversation: The conversation entries\n",
    "        audio_segments: The audio segments\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with information about the saved files\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        output_dir = Path(\"interviews\")\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Format the topic for filenames\n",
    "        formatted_topic = topic.replace(' ', '_').lower()\n",
    "        \n",
    "        # Save the transcript\n",
    "        transcript_path = output_dir / f\"interview_{formatted_topic}_{session_id[:8]}.txt\"\n",
    "        with open(transcript_path, \"w\") as f:\n",
    "            for entry in conversation:\n",
    "                f.write(f\"{entry['speaker']}: {entry['text']}\\n\\n\")\n",
    "        \n",
    "        # Combine and save the audio\n",
    "        audio_path = output_dir / f\"interview_{formatted_topic}_{session_id[:8]}.mp3\"\n",
    "        \n",
    "        if audio_segments:\n",
    "            # Combine all audio segments\n",
    "            combined_audio = audio_segments[0]\n",
    "            for segment in audio_segments[1:]:\n",
    "                # Add a small pause between segments\n",
    "                silence = AudioSegment.silent(duration=500)  # 500ms pause\n",
    "                combined_audio += silence + segment\n",
    "            \n",
    "            # Export the combined audio\n",
    "            combined_audio.export(str(audio_path), format=\"mp3\")\n",
    "            \n",
    "        # Save conversation as JSON for potential future use\n",
    "        json_path = output_dir / f\"interview_{formatted_topic}_{session_id[:8]}.json\"\n",
    "        with open(json_path, \"w\") as f:\n",
    "            json.dump({\n",
    "                \"topic\": topic,\n",
    "                \"session_id\": session_id,\n",
    "                \"conversation\": conversation,\n",
    "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Results saved to {output_dir}\")\n",
    "        \n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"session_id\": session_id,\n",
    "            \"conversation\": conversation,\n",
    "            \"transcript_path\": str(transcript_path),\n",
    "            \"audio_path\": str(audio_path),\n",
    "            \"json_path\": str(json_path)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving results: {e}\")\n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"session_id\": session_id,\n",
    "            \"conversation\": conversation,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "def run_interview(api_key: str, topic: str, num_turns: int = 5) -> Dict[str, Any]:\n",
    "    \"\"\"Run the interview using ADK.\n",
    "    \n",
    "    Args:\n",
    "        api_key: Google Gemini API key\n",
    "        topic: Topic for the interview\n",
    "        num_turns: Number of exchange turns to complete\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with the complete interview information\n",
    "    \"\"\"\n",
    "    # Configure Gemini API\n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Generate a unique session ID\n",
    "    session_id = str(uuid.uuid4())\n",
    "    logger.info(f\"Starting interview session {session_id[:8]} on topic: {topic}\")\n",
    "    \n",
    "    # Set up the agents\n",
    "    expert_agent, interviewer_agent = setup_interview_agents(topic)\n",
    "    \n",
    "    # Set up session and runner\n",
    "    session_service = InMemorySessionService()\n",
    "    runner = Runner(\n",
    "        agent=interviewer_agent,  # Interviewer is the main agent\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service\n",
    "    )\n",
    "    \n",
    "    # Create the session\n",
    "    session = session_service.create_session(\n",
    "        app_name=APP_NAME,\n",
    "        user_id=USER_ID,\n",
    "        session_id=session_id\n",
    "    )\n",
    "    \n",
    "    # Storage for the conversation\n",
    "    conversation = []\n",
    "    audio_segments = []\n",
    "    \n",
    "    # Voice configurations\n",
    "    interviewer_voice = {\n",
    "        \"gender\": texttospeech.SsmlVoiceGender.MALE,\n",
    "        \"language_code\": \"en-US\",\n",
    "        \"speaking_rate\": 1.0\n",
    "    }\n",
    "    \n",
    "    expert_voice = {\n",
    "        \"gender\": texttospeech.SsmlVoiceGender.FEMALE,\n",
    "        \"language_code\": \"en-US\",\n",
    "        \"speaking_rate\": 1.0\n",
    "    }\n",
    "    \n",
    "    # Run the interview\n",
    "    try:\n",
    "        # Initialize the conversation\n",
    "        initial_prompt = f\"Let's conduct an interview about {topic}. Please start by introducing yourself and the topic, then ask your first question to the expert.\"\n",
    "        \n",
    "        content = types.Content(\n",
    "            role='user',\n",
    "            parts=[types.Part(text=initial_prompt)]\n",
    "        )\n",
    "        \n",
    "        # Process the interview in turns\n",
    "        for turn_number in range(num_turns + 1):  # +1 for final closing remarks\n",
    "            logger.info(f\"Starting turn {turn_number}/{num_turns}\")\n",
    "            \n",
    "            # Determine the prompt based on the turn\n",
    "            if turn_number == 0:\n",
    "                # Initial prompt for the first turn\n",
    "                prompt = initial_prompt\n",
    "            elif turn_number == num_turns:\n",
    "                # Closing prompt for the last turn\n",
    "                prompt = \"Please wrap up the interview with a final question and closing remarks.\"\n",
    "            else:\n",
    "                # Continuation prompt for middle turns\n",
    "                prompt = \"Please continue the interview with your next question.\"\n",
    "            \n",
    "            # Create the message content\n",
    "            content = types.Content(\n",
    "                role='user',\n",
    "                parts=[types.Part(text=prompt)]\n",
    "            )\n",
    "            \n",
    "            # Process all events for this turn\n",
    "            for event in runner.run(\n",
    "                user_id=USER_ID,\n",
    "                session_id=session_id,\n",
    "                new_message=content\n",
    "            ):\n",
    "                process_event(event, conversation, audio_segments, interviewer_voice, expert_voice)\n",
    "            \n",
    "            # Small delay to avoid API rate limits\n",
    "            if turn_number < num_turns:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during interview: {e}\")\n",
    "        # We'll still try to save what we have so far\n",
    "    \n",
    "    # Save the results\n",
    "    results = save_interview_results(topic, session_id, conversation, audio_segments)\n",
    "    logger.info(f\"Interview completed with {len(conversation)} exchanges\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the interview system.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"AI Interview Simulation System\")\n",
    "    parser.add_argument(\"--api_key\", required=True, help=\"Google Gemini API key\")\n",
    "    parser.add_argument(\"--topic\", required=True, help=\"Topic for the interview\")\n",
    "    parser.add_argument(\"--turns\", type=int, default=5, help=\"Number of conversation turns\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Run the interview\n",
    "    try:\n",
    "        results = run_interview(\n",
    "            api_key=args.api_key, \n",
    "            topic=args.topic,\n",
    "            num_turns=args.turns\n",
    "        )\n",
    "        \n",
    "        # Print summary information\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Interview on '{args.topic}' completed successfully!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        if \"error\" not in results:\n",
    "            print(f\"\\nTranscript saved to: {results['transcript_path']}\")\n",
    "            print(f\"Audio saved to: {results['audio_path']}\")\n",
    "            print(f\"JSON data saved to: {results['json_path']}\")\n",
    "            \n",
    "            # Print a sample of the conversation\n",
    "            print(\"\\nSample of the conversation:\")\n",
    "            for i, entry in enumerate(results['conversation'][:4]):\n",
    "                print(f\"{entry['speaker']}: {entry['text']}\")\n",
    "                if i < 3:\n",
    "                    print()\n",
    "        else:\n",
    "            print(f\"\\nWarning: Encountered an error: {results['error']}\")\n",
    "            print(f\"Partial conversation with {len(results['conversation'])} exchanges was saved.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error running interview: {e}\")\n",
    "        print(\"Please check logs for more details.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
